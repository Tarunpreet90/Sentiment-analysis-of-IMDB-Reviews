{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import os\n",
    "import re\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from numpy import array\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load IMDB Reviews Dataset\n",
    "\n",
    "df = pd.read_csv(\"/home/tarunpreet/IMDB_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sentiment Analysis using VADER pre-built lexicon-based sentiment analysis tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/tarunpreet/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VADER pre-built, lexicon-based sentiment analysis tool\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       A wonderful little production. <br /><br />The...\n",
      "sentiment                                             positive\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.053, 'neu': 0.776, 'pos': 0.172, 'compound': 0.9641}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.iloc[1])\n",
    "sid.polarity_scores(df['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.203, 'neu': 0.748, 'pos': 0.048, 'co...</td>\n",
       "      <td>-0.9951</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.053, 'neu': 0.776, 'pos': 0.172, 'co...</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.094, 'neu': 0.714, 'pos': 0.192, 'co...</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>{'neg': 0.138, 'neu': 0.797, 'pos': 0.065, 'co...</td>\n",
       "      <td>-0.9213</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>{'neg': 0.052, 'neu': 0.801, 'pos': 0.147, 'co...</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                              scores  compound comp_score  \n",
       "0  {'neg': 0.203, 'neu': 0.748, 'pos': 0.048, 'co...   -0.9951   negative  \n",
       "1  {'neg': 0.053, 'neu': 0.776, 'pos': 0.172, 'co...    0.9641   positive  \n",
       "2  {'neg': 0.094, 'neu': 0.714, 'pos': 0.192, 'co...    0.9605   positive  \n",
       "3  {'neg': 0.138, 'neu': 0.797, 'pos': 0.065, 'co...   -0.9213   negative  \n",
       "4  {'neg': 0.052, 'neu': 0.801, 'pos': 0.147, 'co...    0.9744   positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))\n",
    "df['compound']  = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df['comp_score'] = df['compound'].apply(lambda c: 'positive' if c >=0 else 'negative')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] =  np.array(list(map(lambda x: 1 if x==\"positive\" else 0,df['sentiment'] )))\n",
    "df['comp_score']= np.array(list(map(lambda x: 1 if x==\"positive\" else 0, df['comp_score'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 69.626 %\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.54      0.64     25000\n",
      "           1       0.65      0.86      0.74     25000\n",
      "\n",
      "    accuracy                           0.70     50000\n",
      "   macro avg       0.72      0.70      0.69     50000\n",
      "weighted avg       0.72      0.70      0.69     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CR=classification_report(df['sentiment'],df['comp_score'])\n",
    "print(\"Accuracy : {} %\".format(round(accuracy_score(df['sentiment'],df['comp_score'])*100, 4)))\n",
    "print(\"Classification Report\",CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sentiment analysis using Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tarunpreet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/tarunpreet/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download NLTK Libraries\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove HTML Tags\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(text):\n",
    "     return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre-Processing \n",
    "\n",
    "def preprocess_text(sen):\n",
    "    \n",
    "    #'''Cleans text data up, leaving only 2 or more char long non-stepwords composed of A-Z & a-z onlyin lowercase'''\n",
    "    sentence = sen.lower()\n",
    "    \n",
    "    # Remove html tags\n",
    "    sentence = remove_tags(sentence)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    \n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)  # When we remove apostrophe from the word \"Mark's\", the apostrophe is replaced by an empty space. Hence, we are left with single character \"s\" that we are removing here.\n",
    "   \n",
    "    # Remove multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)  # Next, we remove all the single characters and replace it by a space which creates multiple spaces in our text. Finally, we remove the multiple spaces from our text as well.\n",
    "\n",
    "    # Remove Stopwords\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "    sentence = pattern.sub('', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(df['review'])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting sentiment labels to 0 & 1\n",
    "\n",
    "y = df['sentiment']\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting sentences or documents into numerical vectors \n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf = True,lowercase = True,strip_accents='ascii')\n",
    "X_vec = vectorizer.fit_transform(df[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1: Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4961\n",
      "           1       0.85      0.85      0.85      5039\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "Accuracy : 84.75 %\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "CR=classification_report(y_test, y_pred_rf)\n",
    "print(\"Classification Report\",CR)\n",
    "print(\"Accuracy : {} %\".format(round(accuracy_score(y_test, y_pred_rf)*100, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2: XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      4961\n",
      "           1       0.86      0.88      0.87      5039\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Accuracy : 86.42 %\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "CR=classification_report(y_test, y_pred_xgb)\n",
    "print(\"Classification Report\",CR)\n",
    "print(\"Accuracy : {} %\".format(round(accuracy_score(y_test, y_pred_xgb)*100, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sentiment Analysis using Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,SimpleRNN, LSTM, Dropout,Bidirectional,Activation, Dropout\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, Dropout,Bidirectional\n",
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, GlobalMaxPooling1D, Embedding, Conv1D, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert words to tokens\n",
    "\n",
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(X_train)\n",
    "X_train = word_tokenizer.texts_to_sequences(X_train)\n",
    "X_test = word_tokenizer.texts_to_sequences(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sentence length\n",
    "\n",
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "max_length = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1: Simple Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 100)          8737200   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 10000)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 10001     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8747201 (33.37 MB)\n",
      "Trainable params: 8747201 (33.37 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "469/469 [==============================] - 0s 732us/step - loss: 0.6937 - acc: 0.4896\n",
      "469/469 [==============================] - 0s 633us/step\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.63      0.55      7411\n",
      "           1       0.49      0.35      0.41      7589\n",
      "\n",
      "    accuracy                           0.49     15000\n",
      "   macro avg       0.49      0.49      0.48     15000\n",
      "weighted avg       0.49      0.49      0.48     15000\n",
      "\n",
      "Test Accuracy: 0.4896000027656555\n"
     ]
    }
   ],
   "source": [
    "snn_model = Sequential()\n",
    "embedding_layer = Embedding(vocab_length, 100, input_length=max_length , trainable=True)\n",
    "snn_model.add(embedding_layer)\n",
    "snn_model.add(Flatten())\n",
    "snn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Model compiling\n",
    "snn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(snn_model.summary())\n",
    "\n",
    "score = snn_model.evaluate(X_test, y_test, verbose=1)\n",
    "y_pred_snn = snn_model.predict(X_test)\n",
    "y_pred_labels = (y_pred_snn > 0.5).astype(int)\n",
    "CR=classification_report(y_test, y_pred_labels)\n",
    "print(\"Classification Report\",CR)\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2: Convolutional Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 100)          8737200   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 96, 128)           64128     \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 128)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8811697 (33.61 MB)\n",
      "Trainable params: 8811697 (33.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "219/219 [==============================] - 24s 107ms/step - loss: 0.4389 - acc: 0.7846 - val_loss: 0.3027 - val_acc: 0.8680\n",
      "Epoch 2/6\n",
      "219/219 [==============================] - 23s 104ms/step - loss: 0.1490 - acc: 0.9467 - val_loss: 0.3017 - val_acc: 0.8760\n",
      "Epoch 3/6\n",
      "219/219 [==============================] - 23s 104ms/step - loss: 0.0175 - acc: 0.9967 - val_loss: 0.3791 - val_acc: 0.8779\n",
      "Epoch 4/6\n",
      "219/219 [==============================] - 23s 104ms/step - loss: 0.0014 - acc: 0.9999 - val_loss: 0.4231 - val_acc: 0.8770\n",
      "Epoch 5/6\n",
      "219/219 [==============================] - 23s 104ms/step - loss: 3.4479e-04 - acc: 1.0000 - val_loss: 0.4501 - val_acc: 0.8784\n",
      "Epoch 6/6\n",
      "219/219 [==============================] - 23s 104ms/step - loss: 1.8864e-04 - acc: 1.0000 - val_loss: 0.4705 - val_acc: 0.8781\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4764 - acc: 0.8757\n",
      "469/469 [==============================] - 1s 2ms/step\n",
      "Classification Report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      7411\n",
      "           1       0.88      0.88      0.88      7589\n",
      "\n",
      "    accuracy                           0.88     15000\n",
      "   macro avg       0.88      0.88      0.88     15000\n",
      "weighted avg       0.88      0.88      0.88     15000\n",
      "\n",
      "Test Accuracy: 0.8757333159446716\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D\n",
    "\n",
    "cnn_model = Sequential()\n",
    "embedding_layer = Embedding(vocab_length, 100, input_length=max_length , trainable=True)\n",
    "cnn_model.add(embedding_layer)\n",
    "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(units = 64, activation = 'relu'))\n",
    "cnn_model.add(Dense(units = 32,activation = 'relu'))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Model compiling\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(cnn_model.summary())\n",
    "\n",
    "cnn_model_history = cnn_model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
    "score = cnn_model.evaluate(X_test, y_test, verbose=1)\n",
    "y_pred_cnn = cnn_model.predict(X_test)\n",
    "y_pred_labels = (y_pred_cnn > 0.5).astype(int)\n",
    "CR=classification_report(y_test, y_pred_labels)\n",
    "print(\"Classification Report\",CR)\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
